{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Imports and setup** \n",
    "Import packages, the config.py and architecture.py files and set global parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import *\n",
    "# from architecture import *\n",
    "\n",
    "from pkasolver import data, chem, ml, stat, ml_architecture\n",
    "from pkasolver import constants as c\n",
    "from pkasolver.ml_architecture import GCN_pair, GCN_prot, GCN_deprot, NNConv_pair, NNConv_deprot, NNConv_prot, gcn_full_training\n",
    "\n",
    "import pickle\n",
    "import os\n",
    "import sys\n",
    "import random \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.figsize']= (6.25,6.25)\n",
    "sns.set_theme(style='ticks')\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "import torch\n",
    "from torch import optim\n",
    "from captum.attr import IntegratedGradients\n",
    "from rdkit import Chem\n",
    "\n",
    "from rdkit.Chem import Draw\n",
    "\n",
    "random.seed(SEED)\n",
    "imgdir = 'images_and_tables'\n",
    "os.makedirs(imgdir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Data Preprocessing**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Import raw data**\n",
    "Load data from sdf files, create conjugate molescules and store them in pandas DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['Novartis', 'Literature', 'train_split', 'val_split'])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pKa</th>\n",
       "      <th>marvin_pKa</th>\n",
       "      <th>marvin_atom</th>\n",
       "      <th>marvin_pKa_type</th>\n",
       "      <th>original_dataset</th>\n",
       "      <th>ID</th>\n",
       "      <th>smiles</th>\n",
       "      <th>protonated</th>\n",
       "      <th>deprotonated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>536</th>\n",
       "      <td>9.7</td>\n",
       "      <td>9.63</td>\n",
       "      <td>4</td>\n",
       "      <td>basic</td>\n",
       "      <td>['chembl25']</td>\n",
       "      <td>871123</td>\n",
       "      <td>CC(C)(C)[NH2+]CC(O)c1cc(Cl)c(N)c(C(F)(F)F)c1</td>\n",
       "      <td><img data-content=\"rdkit/molecule\" src=\"data:image/png;base64,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\" alt=\"Mol\"/></td>\n",
       "      <td><img data-content=\"rdkit/molecule\" src=\"data:image/png;base64,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\" alt=\"Mol\"/></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     pKa marvin_pKa marvin_atom marvin_pKa_type original_dataset      ID  \\\n",
       "536  9.7       9.63           4           basic     ['chembl25']  871123   \n",
       "\n",
       "                                           smiles  \\\n",
       "536  CC(C)(C)[NH2+]CC(O)c1cc(Cl)c(N)c(C(F)(F)F)c1   \n",
       "\n",
       "                                            protonated  \\\n",
       "536  <img data-content=\"rdkit/molecule\" src=\"data:i...   \n",
       "\n",
       "                                          deprotonated  \n",
       "536  <img data-content=\"rdkit/molecule\" src=\"data:i...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#make sure the directory for saving the run data exists\n",
    "os.makedirs('run_data/', exist_ok=True)\n",
    "\n",
    "#check if saved dictonary of Dataframes is available and if so, import it\n",
    "if os.path.isfile('run_data/data_dfs.pkl'):\n",
    "    with open('run_data/data_dfs.pkl', 'rb') as pickle_file:\n",
    "        data_dfs = pickle.load(pickle_file)\n",
    "        \n",
    "#create DataFrames for each dataset, store them in a dictonary and save it as as .pkl file in in the run_data folder  \n",
    "else:\n",
    "    data_paths = {'Training':SDF_TRAIN}\n",
    "    for path, name in zip(SDF_TEST,TEST_NAMES):\n",
    "        data_paths[name]=path\n",
    "\n",
    "    data_dfs = data.preprocess_all(data_paths, title='pd_all_datasets')\n",
    "    data_dfs['train_split'], data_dfs['val_split'] = data.train_test_split_df(data_dfs['Training'], TRAIN_TEST_SPLIT, SEED)\n",
    "    data_dfs.pop('Training')\n",
    "\n",
    "    os.makedirs('run_data/', exist_ok=True)\n",
    "    with open('run_data/data_dfs.pkl', 'wb') as pickle_file:\n",
    "        pickle.dump(data_dfs,pickle_file)\n",
    "\n",
    "#notification            \n",
    "print(data_dfs.keys())\n",
    "display(data_dfs['train_split'].head(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Calulate fingerprint based data**\n",
    "Create Fingerprints, target-value objects and add best tanimoto similarities of fps form external validation set molecules with those of the train molecules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fp_data keys: dict_keys(['Novartis', 'Literature', 'train_split', 'val_split'])\n",
      "calculated/loaded fingerprint data successfully\n"
     ]
    }
   ],
   "source": [
    "#check if saved dictonary of fingerprint data is available and if so, import it \n",
    "if os.path.isfile('run_data/fp_data.pkl'):\n",
    "    with open('run_data/fp_data.pkl', 'rb') as pickle_file:\n",
    "        fp_data = pickle.load(pickle_file)\n",
    "\n",
    "\n",
    "#create fingerprint arrays (dim: num molecules x fp bits) for each dataset, store them in a dictonary and save it as as .pkl file in in the run_data folder\n",
    "else:\n",
    "    fp_data = {}\n",
    "    for name, df in data_dfs.items():\n",
    "        X_feat, y = data.make_stat_variables(df, [],[\"pKa\"])\n",
    "        X_prot = chem.morgan_fp_array(df, 'protonated', nBits=FP_BITS, radius=FP_RADIUS, useFeatures=True )\n",
    "        X_deprot= chem.morgan_fp_array(df, 'deprotonated', nBits=FP_BITS, radius=FP_RADIUS, useFeatures=True)\n",
    "        X = np.concatenate((X_prot, X_deprot), axis=1)\n",
    "        fp_data[f'{name}']={\n",
    "            'prot':X_prot,\n",
    "            'deprot':X_deprot,\n",
    "            'pair':X,\n",
    "            'y':y\n",
    "        }\n",
    "\n",
    "    with open('run_data/fp_data.pkl', 'wb') as pickle_file:\n",
    "        pickle.dump(fp_data,pickle_file)\n",
    "\n",
    "    #add max tanimotosimilarity to the Dataframes of external test sets\n",
    "    train_name= 'train_split'\n",
    "    val_name='val_split'\n",
    "    for name, dataset in fp_data.items():\n",
    "        if name in [train_name, val_name]:\n",
    "            pass\n",
    "        else:\n",
    "            print(f'calculating similarities for {name}')\n",
    "            max_scores=[]\n",
    "            for test_mol in dataset['prot']:\n",
    "                scores=[]\n",
    "                for ref_mol in fp_data[train_name]['prot']:\n",
    "                    scores.append(chem.tanimoto(test_mol, ref_mol))\n",
    "                max_scores.append(max(scores))\n",
    "            data_dfs[name]['Similarity_max'] = max_scores\n",
    "    \n",
    "    with open('run_data/data_dfs.pkl', 'wb') as pickle_file:\n",
    "        pickle.dump(data_dfs,pickle_file)\n",
    "\n",
    "#notification\n",
    "print('fp_data keys:',fp_data.keys())\n",
    "print(f'calculated/loaded fingerprint data successfully')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Calculate graph data**\n",
    "Create graph data with node and edge features specified in the config file and prepare loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph_data keys: dict_keys(['Novartis', 'Literature', 'train_split', 'val_split'])\n",
      "loaders keys: dict_keys(['Novartis', 'Literature', 'train_split', 'val_split'])\n",
      "calculated/loaded graph data successfully\n"
     ]
    }
   ],
   "source": [
    "#check if saved dictonary of graph data is available and if so, import it \n",
    "if os.path.isfile('run_data/graph_data.pkl'):\n",
    "    with open('run_data/graph_data.pkl', 'rb') as pickle_file:\n",
    "        graph_data = pickle.load(pickle_file)\n",
    "\n",
    "# create list of 'PairData' graph objects for each dataset, store them in a dictonary and save it as as .pkl file in in the run_data folder\n",
    "else:\n",
    "    graph_data = {}\n",
    "    for name, df in data_dfs.items():\n",
    "        graph_data[name]= data.make_pyg_dataset_based_on_number_of_hydrogens(df, NODE_FEATURES, EDGE_FEATURES, paired=True)\n",
    "        \n",
    "    with open('run_data/graph_data.pkl', 'wb') as pickle_file:\n",
    "        pickle.dump(graph_data,pickle_file)\n",
    "\n",
    "print('graph_data keys:',graph_data.keys())        \n",
    "\n",
    "# create an iterable loader object from the list of graph data of each dataset and store them in a dictonary\n",
    "loaders = {}\n",
    "for name, dataset in graph_data.items():\n",
    "    loaders[name] = ml.dataset_to_dataloader(dataset, BATCH_SIZE)\n",
    "\n",
    "#notification    \n",
    "print('loaders keys:',loaders.keys())  \n",
    "print(f'calculated/loaded graph data successfully')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Batch(ID=[64], batch=[1057], charge_deprot=[64], charge_prot=[64], edge_attr_d=[2220, 3], edge_attr_p=[2220, 3], edge_index_d=[2, 2220], edge_index_p=[2, 2220], x_d=[1057, 8], x_d_batch=[1057], x_p=[1057, 8], x_p_batch=[1057], y=[64])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(loaders['train_split']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**show feature value range**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node features:\n",
      "atomic_number:[1.0, 6.0, 7.0, 8.0, 9.0, 15.0, 16.0, 17.0, 33.0, 35.0, 53.0]\n",
      "formal_charge:[-1.0, 0.0, 1.0]\n",
      "hybridization:[1.0, 2.0, 3.0, 4.0]\n",
      "total_num_Hs:[0.0, 1.0, 2.0, 3.0]\n",
      "aromatic_tag:[0.0, 1.0]\n",
      "total_valence:[1.0, 2.0, 3.0, 4.0, 5.0, 6.0]\n",
      "total_degree:[1.0, 2.0, 3.0, 4.0]\n",
      "is_in_ring:[0.0, 1.0]\n",
      "\n",
      "\n",
      "Edge features:\n",
      "bond_type:[1.0, 1.5, 2.0, 3.0]\n",
      "is_conjugated:[0.0, 1.0]\n",
      "rotatable:[0.0, 1.0]\n"
     ]
    }
   ],
   "source": [
    "#print all possible node feature values\n",
    "values= [set() for i in range(len(NODE_FEATURES))]\n",
    "for dataset in graph_data.values():     \n",
    "    for entry in dataset:\n",
    "        for i, row in enumerate(entry.x_p.cpu().T):\n",
    "            values[i]= values[i]|set(row.numpy())\n",
    "        for i, row in enumerate(entry.x_d.cpu().T):\n",
    "            values[i]= values[i]|set(row.numpy())\n",
    "print('Node features:')\n",
    "for name, values in zip(NODE_FEATURES,values):\n",
    "    x= list(values)\n",
    "    x.sort()\n",
    "    print(f'{name}:{x}')\n",
    "print('\\n')\n",
    "\n",
    "#print all possible edge feature values\n",
    "values= [set() for i in range(len(EDGE_FEATURES))]\n",
    "for dataset in graph_data.values():     \n",
    "    for entry in dataset:\n",
    "        for i, row in enumerate(entry.edge_attr_p.cpu().T):\n",
    "            values[i]= values[i]|set(row.numpy())\n",
    "        for i, row in enumerate(entry.edge_attr_d.cpu().T):\n",
    "            values[i]= values[i]|set(row.numpy())\n",
    "print('Edge features:')\n",
    "for name, values in zip(EDGE_FEATURES,values):\n",
    "    x= list(values)\n",
    "    x.sort()\n",
    "    print(f'{name}:{x}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PairData(ID=\"pka_pot_352_1\", charge_deprot=0, charge_prot=1, edge_attr_d=[34, 3], edge_attr_p=[34, 3], edge_index_d=[2, 34], edge_index_p=[2, 34], x_d=[15, 8], x_p=[15, 8], y=[1])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(graph_data.values()))[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Training of predictive models**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **train baseline models**\n",
    "train all baseline models in protonated, deprotonated and pair mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trained/loaded baseline models successfully\n"
     ]
    }
   ],
   "source": [
    "models_dict = {\n",
    "        'RFR':RandomForestRegressor(n_estimators=NUM_ESTIMATORS, random_state=SEED),  #Baltruschat n_estimatores = 1000\n",
    "        'PLS':PLSRegression()\n",
    "    }\n",
    "\n",
    "baseline_models = {}\n",
    "train_name='train_split'\n",
    "val_name='val_split'\n",
    "\n",
    "for model_name, model_template in models_dict.items():\n",
    "    baseline_models[model_name]={}\n",
    "    for mode, X in fp_data[train_name].items():\n",
    "        if mode == 'y':\n",
    "            continue\n",
    "        path = f'models/baseline/{model_name}/{mode}/'\n",
    "        if os.path.isfile(path+'model.pkl'):\n",
    "            with open(path+'model.pkl', 'rb') as pickle_file:\n",
    "                baseline_models[model_name][mode] = pickle.load(pickle_file)\n",
    "        else:\n",
    "            y = fp_data[train_name]['y']\n",
    "            y_val = fp_data[val_name]['y']\n",
    "            model = copy.deepcopy(model_template)\n",
    "            model.fit(X,y)\n",
    "            print(f'{model_name}_{mode}: {model.score(fp_data[val_name][mode], y_val)}')\n",
    "            baseline_models[model_name][mode] = model\n",
    "            os.makedirs(path, exist_ok=True)\n",
    "            with open(path+'model.pkl', 'wb') as pickle_file:\n",
    "                pickle.dump(model,pickle_file)\n",
    "print(f'trained/loaded baseline models successfully')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **train graph models**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Training**\n",
    "train all graph models in protonated, deprotonated and pair mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training GCN_prot with no-edge at epoch 0...\n",
      "Epoch: 000, Train MAE: 6.6910, Test MAE: 6.8340\n",
      "Epoch: 002, Train MAE: 1.9640, Test MAE: 1.9600\n",
      "Epoch: 004, Train MAE: 1.9670, Test MAE: 1.9610\n",
      "Training GCN_prot with edge at epoch 0...\n",
      "Epoch: 000, Train MAE: 298.7240, Test MAE: 306.8630\n",
      "Epoch: 002, Train MAE: 2.7530, Test MAE: 2.7740\n",
      "Epoch: 004, Train MAE: 2.1180, Test MAE: 2.1250\n",
      "Training GCN_deprot with no-edge at epoch 0...\n",
      "Epoch: 000, Train MAE: 6.6920, Test MAE: 6.8360\n",
      "Epoch: 002, Train MAE: 1.9880, Test MAE: 1.9820\n",
      "Epoch: 004, Train MAE: 2.0080, Test MAE: 2.0050\n",
      "Training GCN_deprot with edge at epoch 0...\n",
      "Epoch: 000, Train MAE: 297.6440, Test MAE: 305.6360\n",
      "Epoch: 002, Train MAE: 2.9990, Test MAE: 2.9740\n",
      "Epoch: 004, Train MAE: 2.3170, Test MAE: 2.3010\n",
      "Training GCN_pair with no-edge at epoch 0...\n",
      "Epoch: 000, Train MAE: 6.9560, Test MAE: 7.1000\n",
      "Epoch: 002, Train MAE: 1.9710, Test MAE: 1.9640\n",
      "Epoch: 004, Train MAE: 1.9150, Test MAE: 1.9050\n",
      "Training GCN_pair with edge at epoch 0...\n",
      "Epoch: 000, Train MAE: 325.5500, Test MAE: 333.6980\n",
      "Epoch: 002, Train MAE: 2.8970, Test MAE: 2.8250\n",
      "Epoch: 004, Train MAE: 2.3310, Test MAE: 2.3340\n",
      "trained/loaded gcn models successfully\n"
     ]
    }
   ],
   "source": [
    "embedding_size=96\n",
    "num_graph_layer=4 \n",
    "num_linear_layer=2\n",
    "\n",
    "gcn_dict= {\n",
    "    'prot':{\n",
    "        'no-edge':GCN_prot,\n",
    "        'edge':NNConv_prot\n",
    "    },\n",
    "    'deprot':{\n",
    "        'no-edge':GCN_deprot,\n",
    "        'edge':NNConv_deprot\n",
    "    },\n",
    "    'pair':{\n",
    "        'no-edge':GCN_pair,\n",
    "        'edge':NNConv_pair\n",
    "    }\n",
    "}\n",
    "\n",
    "mol_modes=['prot','deprot','pair']\n",
    "edge_modes=['no-edge', 'edge']\n",
    "\n",
    "graph_models = {}\n",
    "for mode in mol_modes:\n",
    "    graph_models[mode] ={}\n",
    "    for edge in edge_modes:\n",
    "        path = f'models/gcn/{mode}/{edge}/'\n",
    "        if os.path.isfile(path+'model.pkl'):\n",
    "            with open(path+'model.pkl', 'rb') as pickle_file:\n",
    "                graph_models[mode][edge] = pickle.load(pickle_file)\n",
    "            model = graph_models[mode][edge]\n",
    "        else:\n",
    "            model = gcn_dict[mode][edge](96,4,2).to(device=DEVICE)\n",
    "            graph_models[mode][edge] = model\n",
    "            \n",
    "            os.makedirs(path, exist_ok=True)\n",
    "        if model.checkpoint['epoch'] < NUM_EPOCHS:   \n",
    "            optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "            try:\n",
    "                optimizer.load_state_dict(model.checkpoint['optimizer_state'])    \n",
    "            except:\n",
    "                pass\n",
    "            scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=5, verbose=True)\n",
    "\n",
    "            print(f'Training GCN_{mode} with {edge} at epoch {model.checkpoint[\"epoch\"]}...')\n",
    "            gcn_full_training(model,loaders['train_split'],loaders['val_split'], optimizer, path)\n",
    "\n",
    "            with open(path+'model.pkl', 'wb') as pickle_file:\n",
    "                pickle.dump(model,pickle_file)\n",
    "                \n",
    "print(f'trained/loaded gcn models successfully')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Cross validation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **prepare graph and fp data for cv**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_graph_data = data.slice_list(graph_data['train_split']+graph_data['val_split'],5)\n",
    "# cv_graph_train, cv_graph_val = data.cross_val_lists(cv_graph_data,run_cv)\n",
    "\n",
    "cv_loaders={'train':{},'val':{}}\n",
    "for i in range(5):\n",
    "    train, val = data.cross_val_lists(cv_graph_data,i)\n",
    "    cv_loaders['train'][i] = ml.dataset_to_dataloader(train, BATCH_SIZE)\n",
    "    cv_loaders['val'][i] = ml.dataset_to_dataloader(val, BATCH_SIZE)\n",
    "\n",
    "for name, nums in cv_loaders.items():\n",
    "    for num, obj in nums.items(): \n",
    "        print('graph_data: ',name, num, obj)\n",
    "        \n",
    "#create dictionary with modes as keys and a list of 5 arrays for each value\n",
    "cv_fp_data={}\n",
    "for name, array in fp_data['train_split'].items():\n",
    "    try:\n",
    "        cv_fp_data[name]=np.vstack((array,fp_data['val_split'][name]))\n",
    "    except:\n",
    "        cv_fp_data[name]=np.hstack((array,fp_data['val_split'][name]))\n",
    "for name, array in cv_fp_data.items():\n",
    "    cv_fp_data[name] = data.slice_list(array,5)\n",
    "\n",
    "#generate \n",
    "cv_fp_sets={'train':{},'val':{}}\n",
    "for i in range(5):\n",
    "    cv_fp_train={}\n",
    "    cv_fp_val={}\n",
    "    for name, array in cv_fp_data.items():\n",
    "        train, val = data.cross_val_lists(array,i)\n",
    "        cv_fp_train[name] = np.array(train, dtype=object)\n",
    "        cv_fp_val[name] = np.array(val, dtype=object)\n",
    "    cv_fp_sets['train'][i]=cv_fp_train\n",
    "    cv_fp_sets['val'][i]=cv_fp_val\n",
    "    \n",
    "for name, nums in cv_fp_sets.items():\n",
    "    for num, modes in nums.items():\n",
    "        print('fp_data: ',name, num, modes.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **load baseline and gcn models for cv**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mol_modes=['prot','deprot','pair']\n",
    "edge_modes=['no-edge','edge']\n",
    "cv = list(range(5))\n",
    "\n",
    "graph_models_cv = {}\n",
    "for mode in mol_modes:\n",
    "    graph_models_cv[mode] ={}\n",
    "    for edge in edge_modes:\n",
    "        graph_models_cv[mode][edge] = {}\n",
    "        for num_cv in cv: \n",
    "            path = f'cv_models/gcn/{mode}/{edge}/{num_cv}/'\n",
    "            if os.path.isfile(path+'model.pkl'):\n",
    "                with open(path+'model.pkl', 'rb') as pickle_file:\n",
    "                    graph_models_cv[mode][edge][num_cv] = pickle.load(pickle_file)\n",
    "                model = graph_models_cv[mode][edge][num_cv]\n",
    "            else:\n",
    "                print(f'cv_models/gcn/{mode}/{edge}/{num_cv}/ not found')\n",
    "\n",
    "baseline_models_cv = {}\n",
    "for name in models_dict.keys():\n",
    "    baseline_models_cv[name]={}\n",
    "    for mode in mol_modes:\n",
    "        baseline_models_cv[name][mode] ={}\n",
    "        for num_cv in cv: \n",
    "            path = f'cv_models/baseline/{name}/{mode}/{num_cv}/'\n",
    "            if os.path.isfile(path+'model.pkl'):\n",
    "                with open(path+'model.pkl', 'rb') as pickle_file:\n",
    "                    baseline_models_cv[name][mode][num_cv] = pickle.load(pickle_file)\n",
    "            else:\n",
    "                print(f'cv_models/baseline/{name}/{mode}/{num_cv}/ not found')\n",
    "                \n",
    "for name, modes in graph_models_cv.items():\n",
    "    for mode in modes.keys():\n",
    "        print('gcn: ',name, mode)\n",
    "for name, modes in baseline_models_cv.items():\n",
    "    for mode in modes.keys():\n",
    "        print('baseline: ',name, mode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load bestmodels**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_treshold = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mol_modes=['prot','deprot','pair']\n",
    "edge_modes=['no-edge','edge']\n",
    "cv = list(range(5))\n",
    "\n",
    "graph_models_cv = {}\n",
    "for mode in mol_modes:\n",
    "    graph_models_cv[mode] ={}\n",
    "    for edge in edge_modes:\n",
    "        graph_models_cv[mode][edge] = {}\n",
    "        for num_cv in cv: \n",
    "            path = f'cv_models/gcn/{mode}/{edge}/{num_cv}/'\n",
    "            if os.path.isfile(path+'model.pkl'):\n",
    "                with open(path+'model.pkl', 'rb') as pickle_file:\n",
    "                    model = pickle.load(pickle_file)\n",
    "                best_loss = max([x for x in model.checkpoint['best_states'].keys() if x < epoch_treshold]) \n",
    "                model.load_state_dict(model.checkpoint['best_states'][best_loss][1])\n",
    "                loss = model.checkpoint['best_states'][best_loss][0]\n",
    "                print(f'GCN_{mode}_{edge}_{num_cv},Epoch {best_loss}, Loss:{loss}')\n",
    "                graph_models_cv[mode][edge][num_cv] = model\n",
    "            else:\n",
    "                print(f'{path} not found')\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_models = {}\n",
    "for mode in mol_modes:\n",
    "    graph_models[mode] ={}\n",
    "    for edge in edge_modes:\n",
    "        graph_models[mode][edge] = {} \n",
    "        path = f'models/gcn/{mode}/{edge}/'\n",
    "        if os.path.isfile(path+'model.pkl'):\n",
    "            with open(path+'model.pkl', 'rb') as pickle_file:\n",
    "                model = pickle.load(pickle_file)\n",
    "            best_loss = max([x for x in model.checkpoint['best_states'].keys() if x < epoch_treshold]) \n",
    "            model.load_state_dict(model.checkpoint['best_states'][best_loss][1])\n",
    "            loss = model.checkpoint['best_states'][best_loss][0]\n",
    "            print(f'GCN_{mode}_{edge},Epoch {best_loss}, Loss:{loss}')\n",
    "            graph_models[mode][edge] = model\n",
    "        else:\n",
    "            print(f'{path} not found')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Results and Analysis**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Test Baseline and Graph Models**\n",
    "test the models and the valadation and the two external sets and store their predictions and the true valus in a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predictions of baseline and graph models\n",
    "\n",
    "for i,test_set in enumerate(['Novartis','Literature','val_split']):\n",
    "    df_ml = ml.test_ml_model(baseline_models, fp_data[test_set], fp_data[test_set]['y'],test_set)\n",
    "    df_gcn = ml.test_graph_model(graph_models, loaders[test_set],test_set)\n",
    "    df= pd.concat([df_ml,df_gcn.drop(columns=['Dataset', 'pKa_true'])],axis=1)\n",
    "    if i == 0:\n",
    "        df_res = df\n",
    "    else:\n",
    "        df_res = pd.concat([df_res,df])\n",
    "display(df_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Statistical metrics**\n",
    "Calulate the Pearson Correlation Koefficient, the Root Mean Squared Error and the Mean absolute error of the validation and the two test sets for all models and list them in a DataFrame "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test= stat.compute_stats(df_res, 'Dataset', 'pKa_true')\n",
    "test.to_csv(f'{imgdir}/stat_metrics.csv')\n",
    "display(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test= stat.compute_stats(df_res, 'Dataset', 'pKa_true')\n",
    "test.to_csv(f'{imgdir}/stat_metrics.csv')\n",
    "display(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **CV results**\n",
    "Load models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_val_table= pd.concat((\n",
    "    stat.cv_graph_model(graph_models_cv,cv_loaders['val']),\n",
    "    stat.cv_ml_model(baseline_models_cv,cv_fp_sets['val'])\n",
    "))\n",
    "cv_val_table.to_csv(f'{imgdir}/cv_val_table.csv')\n",
    "display(cv_val_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d ={}\n",
    "for data_set in ['Novartis','Literature']:\n",
    "    d[data_set]= pd.concat([\n",
    "    stat.cv_ml_model(baseline_models_cv,[fp_data[data_set] for i in range(5)]),\n",
    "    stat.cv_graph_model(graph_models_cv,[loaders[data_set] for i in range(5)])\n",
    "    ])\n",
    "cv_test_table=pd.concat(d.values(), axis=1, keys=d.keys())\n",
    "cv_test_table.to_csv(f'{imgdir}/cv_test_table.csv')\n",
    "cv_test_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Plot best model**\n",
    "Plot the predictions of the best models for the validation and the two testsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(df, x_column, y_column):\n",
    "    y = df[x_column]\n",
    "    y_hat = df[y_column]\n",
    "    stat_info = f\"\"\"\n",
    "        $r^2$ = {r2_score(y, y_hat): .2f}\n",
    "        $MAE$ = {mean_absolute_error(y, y_hat): .2f}\n",
    "        $RMSE$ = {mean_squared_error(y, y_hat): .2f}\n",
    "        \"\"\"\n",
    "        # rÂ² = 0.78 [0.74, 0.81]\n",
    "    g = sns.JointGrid(data=df, x=x_column, y=y_column, xlim=(2,12), ylim=(2,12), height=3.125)\n",
    "    g.plot_joint(sns.regplot)\n",
    "    g.plot_marginals(sns.kdeplot, shade=True)\n",
    "    g.ax_joint.text(0, 1, stat_info, size='x-small', ha='left', va=\"top\", transform = g.ax_joint.transAxes)\n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_context('paper')\n",
    "d = df_res\n",
    "model='GCN_pair_edge'\n",
    "for dataset in d['Dataset'].unique():\n",
    "# for dataset, model in zip(['Novartis','Literature'],['GCN_pair_edge', 'GCN_deprot_no-edge']):\n",
    "    print(dataset)\n",
    "    g = plot_results(d[d['Dataset']== dataset], 'pKa_true', model)\n",
    "    g.set_axis_labels('pKa (true)', 'gcn_pair_edge')\n",
    "    plt.savefig(f'{imgdir}/regression_{dataset}_gcn_pair_edge.pdf', bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    plt.figure(figsize=(3.125,3.125))\n",
    "    sns.residplot(data=df_res[df_res['Dataset']==dataset],x='pKa_true', y=model, lowess=True)\n",
    "    plt.ylabel('Error')\n",
    "#     plt.title('gcn_pair_edge')\n",
    "    plt.savefig(f'{imgdir}/residuals_{dataset}_gcn_pair_edge.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **GCN training progress**\n",
    "store training losses in DataFrame and "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x,y in list([['pair','edge'],['prot','no-edge']]):\n",
    "    df_prog=pd.DataFrame(graph_models[x][y].checkpoint['progress_table'])\n",
    "#     df_prog=pd.DataFrame(graph_models_cv[x][y][1].checkpoint['progress_table'])\n",
    "    #plot learning\n",
    "    fig, ax = plt.subplots()\n",
    "    fig.set_size_inches(3.125,3.125)\n",
    "    sns.lineplot(x='epoch',y='train_loss', label='Train Loss',data=df_prog,ax=ax)\n",
    "    sns.lineplot(x='epoch',y='test_loss',label='Validation Loss',data=df_prog,ax=ax)\n",
    "    ax.set_ylabel(\"Loss (MAE)\")\n",
    "    ax.set_xlabel(\"Epoch\")\n",
    "    ax.set_xlim(left=0, right=2000)\n",
    "    ax.set_ylim(top=1.75, bottom=0)\n",
    "#     plt.title(f'training progress of gcn_{x}_{y} model')\n",
    "    plt.savefig(f'{imgdir}/training_progress_gcn_{x}_{y}.pdf',bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Feature impact**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Importances of gcn_prot_edge'**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def boxplot(attr_data):\n",
    "    plt.figure(figsize=(3.125,6.25))\n",
    "    sns.boxplot(x=\"value\", y=\"variable\",\n",
    "                orient=\"h\",\n",
    "                data=attr_data,\n",
    "                whis=[0, 100], width=.6)\n",
    "\n",
    "    # Add in points to show each observation\n",
    "    sns.stripplot(x=\"value\", y=\"variable\",\n",
    "                orient=\"h\",\n",
    "                data=attr_data,\n",
    "                size=4, color=\".3\", linewidth=0)\n",
    "    plt.ylabel('')\n",
    "\n",
    "types = ['prot','deprot','pair']\n",
    "f_modes= ['no-edge','edge']\n",
    "for data_type in types:\n",
    "    for f_mode in f_modes: \n",
    "        model = graph_models[data_type][f_mode]\n",
    "        dataset = graph_data['train_split']\n",
    "        ig = IntegratedGradients(model)\n",
    "        attr_pre_df = stat.calc_importances(ig, dataset, 100, NODE_FEATURES, EDGE_FEATURES) #adjust number of random samples\n",
    "\n",
    "        attr_pre_df.iloc[:, 1:]=attr_pre_df.iloc[:, 1:].abs()\n",
    "        attr_df=attr_pre_df.groupby('ID').max()\n",
    "        attr_data = pd.melt(attr_df)\n",
    "        \n",
    "        if data_type== 'pair':\n",
    "            split = len(attr_data.variable.unique())//2\n",
    "            attr_data1 = pd.melt(attr_df.iloc[:,0:split])\n",
    "            attr_data2 = pd.melt(attr_df.iloc[:,split:])\n",
    "        \n",
    "            boxplot(attr_data1)\n",
    "#             plt.title(f'gcn_{data_type}_1_{f_mode}')\n",
    "            plt.savefig(f'{imgdir}/importances_{data_type}_1_{f_mode}.pdf', bbox_inches='tight')\n",
    "            plt.show()\n",
    "            boxplot(attr_data2)\n",
    "#             plt.title(f'gcn_{data_type}_2_{f_mode}')\n",
    "            plt.savefig(f'{imgdir}/importances_{data_type}_2_{f_mode}.pdf', bbox_inches='tight')\n",
    "            plt.show()\n",
    "            \n",
    "        else:\n",
    "            boxplot(attr_data)\n",
    "#             plt.title(f'gcn_{data_type}_{f_mode}')\n",
    "            plt.savefig(f'{imgdir}/importances_{data_type}_{f_mode}.pdf', bbox_inches='tight')\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Metrics by tanimoto similarity**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1= pd.concat([df_res[['Dataset', 'pKa_true']],df_res.loc[:,(df_res.columns.str.startswith('GCN'))]],axis=1)\n",
    "for data_set in ['Novartis', 'Literature']:\n",
    "    df = x1[x1['Dataset']==data_set].copy()\n",
    "    df['similarity'] = data_dfs[data_set].loc[:,'Similarity_max']\n",
    "    df.sort_values(by=['similarity'], inplace=True)\n",
    "\n",
    "    res=[]\n",
    "    tanimoto=[]\n",
    "    maximum=0\n",
    "\n",
    "    for i in range(2,len(df)):\n",
    "        df2 = df.iloc[:i,:]\n",
    "        new_maximum = df2['similarity'].max()\n",
    "        if new_maximum <= maximum:\n",
    "            tanimoto[-1]= new_maximum\n",
    "            res[-1]= stat.compute_stats(df2, 'Dataset', 'pKa_true',col_exclude=['similarity'])\n",
    "        else: \n",
    "            tanimoto.append(new_maximum)\n",
    "            res.append(stat.compute_stats(df2, 'Dataset', 'pKa_true', col_exclude=['similarity']))\n",
    "        maximum=new_maximum\n",
    "    result = pd.concat((res), keys=tanimoto)\n",
    "    result\n",
    "\n",
    "    # X=result['Novartis'].loc[(slice(None),'pKa_gcn_prot_edge'),:].reset_index()\n",
    "    X=result[data_set].reset_index()\n",
    "    plt.figure(figsize=(6.25,4))\n",
    "    ax = sns.scatterplot(x='level_0', y=\"RMSE\", hue='level_1', palette='colorblind', data=X)\n",
    "    legend = ax.legend()\n",
    "    legend.texts[0] = ''\n",
    "    plt.xlabel('Similarity')\n",
    "    plt.savefig(f'{imgdir}/RMSE_sim_{data_set}.pdf')\n",
    "    \n",
    "    x2= x1\n",
    "    df = x2[x2['Dataset']==data_set].copy()\n",
    "    df['similarity'] = data_dfs[data_set].loc[:,'Similarity_max']\n",
    "    df.sort_values(by=['similarity'], inplace=True)\n",
    "    \n",
    "    df = df.loc[:,('pKa_true','GCN_pair_edge','similarity')]\n",
    "\n",
    "    df['Error']= df['GCN_pair_edge']-df['pKa_true']\n",
    "\n",
    "    sims=[]\n",
    "    step_size=0.15\n",
    "    for sim in df['similarity']:\n",
    "        x=1\n",
    "        while sim < x:\n",
    "            x+= -step_size\n",
    "        sims.append(f'< {round(np.clip(x+step_size,0,1),3)}')\n",
    "    df['group']=sims            \n",
    "\n",
    "    plt.figure(figsize=(6.25/2,2.5))\n",
    "    sns.boxplot(x=\"group\", y=\"Error\",\n",
    "                orient=\"v\",\n",
    "\n",
    "                whis=[0, 100], width=.6,\n",
    "                data=df\n",
    "               )\n",
    "    # Add in points to show each observation\n",
    "    sns.stripplot(x=\"group\", y=\"Error\",\n",
    "                orient=\"v\",\n",
    "                data=df,\n",
    "                  size=4, color=\".3\", linewidth=0)\n",
    "    plt.xlabel('Similarity')\n",
    "    plt.ylabel('Error [pKa units]')\n",
    "    plt.savefig(f'{imgdir}/error_sim_bloxplot_{data_set}.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Outliers top list**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_2d_molecule(m):\n",
    "  copy = Chem.Mol(m)\n",
    "  copy.Compute2DCoords(clearConfs=True)\n",
    "  return copy\n",
    "\n",
    "def group_by_range(series, range_list, decimal=1):\n",
    "    group_labels=[]\n",
    "    for x in series:\n",
    "        i=0\n",
    "        while x > range_list[i]:\n",
    "            i+=1\n",
    "        group_labels.append(round(range_list[i],decimal))\n",
    "    return group_labels \n",
    "\n",
    "data_set=['Novartis', 'Literature']\n",
    "best=[True, False]\n",
    "for data_set in data_set:\n",
    "    trues= df_res[df_res.Dataset==data_set].pKa_true\n",
    "    preds= df_res[df_res.Dataset==data_set].GCN_pair_edge\n",
    "    diffs = []\n",
    "    errors = []\n",
    "    for pred, true in zip(preds,trues):\n",
    "        diffs.append(pred-true)\n",
    "        errors.append(abs(pred-true))\n",
    "    res = pd.concat((pd.DataFrame({'differences':diffs}),pd.DataFrame({'errors':errors}), data_dfs['Novartis'].loc[:,('pKa','marvin_atom','protonated', 'deprotonated', 'ID','Similarity_max')]),axis=1)\n",
    "    \n",
    "    res_e=res.loc[:, ('errors','pKa','Similarity_max')]\n",
    "    res_e['pKa']=group_by_range(res_e['pKa'],list(range(2,14,2)))\n",
    "    res_e['Similarity']=group_by_range(res['Similarity_max'],np.arange(0.0,1.2,0.2))\n",
    "    res_e=res_e.loc[:, ('errors','pKa','Similarity')]\n",
    "    res_e=res_e.groupby(['Similarity','pKa']).mean().unstack()\n",
    "#     display(res_e)\n",
    "    \n",
    "    plt.figure(figsize=(3.125,2.5))\n",
    "    sns.heatmap(res_e['errors'], cmap='RdYlGn_r', vmin=0,vmax=1.50)\n",
    "    plt.savefig(f'{imgdir}/error_heatmap_{data_set}.pdf', bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    for mod in best:    \n",
    "        res.sort_values(by=['errors'], inplace=True, ascending=mod)\n",
    "        num=6\n",
    "        img=Draw.MolsToGridImage(res.protonated[:num].map(get_2d_molecule),\n",
    "                                 molsPerRow=3,\n",
    "                                 subImgSize=(400,350),\n",
    "                                 useSVG=True,\n",
    "                                 highlightAtomLists=[[int(i)] for i in res.marvin_atom[:num]],\n",
    "                                 legends=[f\"error:  {round(x[1],2)}, pKa:  {x[0]}, sim: {x[2]:.3f}\" for x in zip(res.pKa[:num],res.differences[:num], res.Similarity_max[:num])])\n",
    "\n",
    "        display(img)\n",
    "        name_dict={True:'best',False:'outlier'}\n",
    "        with open(f'{imgdir}/grid_{data_set}_{name_dict[mod]}.svg', 'w') as f:\n",
    "            f.write(img.data)\n",
    "    # res.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
