{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Imports and setup** \n",
    "Import packages, the config.py and architecture.py files and set global parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting num threads to 1\n",
      "Pytorch will use cuda\n"
     ]
    }
   ],
   "source": [
    "from config import (\n",
    "    LEARNING_RATE,\n",
    "    NUM_EPOCHS,\n",
    "    TRAIN_SIZE,\n",
    "    FP_BITS,\n",
    "    FP_RADIUS,\n",
    "    list_node_features,\n",
    "    list_edge_features,\n",
    "    BATCH_SIZE,\n",
    "    NUM_ESTIMATORS,\n",
    "    # num_node_features,\n",
    "    num_edge_features,\n",
    ")\n",
    "from pkasolver.constants import SEED, DEVICE\n",
    "from pkasolver.data import (\n",
    "    load_data,\n",
    "    preprocess_all,\n",
    "    train_validation_set_split,\n",
    "    make_stat_variables,\n",
    "    make_pyg_dataset_from_dataframe,\n",
    "    \n",
    ")\n",
    "from pkasolver.ml_architecture import (\n",
    "    gcn_full_training,\n",
    "    GCNPairSingleConv,\n",
    "    GCNPairTwoConv,\n",
    "    GCNProt,\n",
    "    GCNDeprot,\n",
    "    NNConvPair,\n",
    "    NNConvDeprot,\n",
    "    NNConvProt,\n",
    "\n",
    ")\n",
    "from pkasolver.chem import generate_morgan_fp_array, calculate_tanimoto_coefficient\n",
    "from pkasolver.ml import dataset_to_dataloader, test_ml_model, test_graph_model\n",
    "from pkasolver.stat import compute_stats\n",
    "import random\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (6.25, 6.25)\n",
    "sns.set_theme(style=\"ticks\")\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from IPython.display import display\n",
    "\n",
    "import torch\n",
    "from torch import optim\n",
    "from rdkit.Chem import Draw, Mol\n",
    "random.seed(SEED)\n",
    "imgdir = \"images_and_tables\"\n",
    "os.makedirs(imgdir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(results, title):\n",
    "    plt.plot(results['training-set'], label='training set')\n",
    "    plt.plot(results['validation-set'], label='validation set')\n",
    "    if title:\n",
    "        plt.title(title)\n",
    "    plt.ylim([0,4])\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Data Preprocessing**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Import raw data**\n",
    "Load data from sdf files, create conjugate molescules and store them in pandas DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data ...\n",
      "dict_keys(['Training', 'Novartis', 'Literature', 'train_split', 'val_split'])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pKa</th>\n",
       "      <th>marvin_pKa</th>\n",
       "      <th>marvin_atom</th>\n",
       "      <th>marvin_pKa_type</th>\n",
       "      <th>original_dataset</th>\n",
       "      <th>ID</th>\n",
       "      <th>smiles</th>\n",
       "      <th>protonated</th>\n",
       "      <th>deprotonated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>536</th>\n",
       "      <td>9.7</td>\n",
       "      <td>9.63</td>\n",
       "      <td>4</td>\n",
       "      <td>basic</td>\n",
       "      <td>['chembl25']</td>\n",
       "      <td>871123</td>\n",
       "      <td>CC(C)(C)[NH2+]CC(O)c1cc(Cl)c(N)c(C(F)(F)F)c1</td>\n",
       "      <td><img data-content=\"rdkit/molecule\" src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAMgAAADICAIAAAAiOjnJAAAABmJLR0QA/wD/AP+gvaeTAAAWcklEQVR4nO3dfVyN9/8H8Pc5dY5OhG6URTFJU4aEWWSzNn3303c3ZixfGd8vxoOlMGkbMd9ZxqYZ9q1hMmuNoZk98HAzC7NxurFFcZDu5KTbkzqdu+vz++NKIt2d6/qc66rez8f+cG76fN7x2nX7+XwuCSEEEOKbVOgCUMeEwUJUYLAQFRgsRAUGC1GBwUJUYLAQFRgsRAUGC1GBwUJUYLAQFRgsRAUGC1GBwUJUYLAQFRgsRAUGC1GBwUJUYLAQFRgsRAUGC1GBwUJUYLAQFRgsRAUGC1GBwUJUYLAQFRgsRAUGC1GBwUJUYLAQFRgsRAUGC1GBwUJUYLAQFRgsRAUGC1GBwUJUYLAQFRgsRAUGC1EhlmAZiVFHdEJXgXhjLVTHWka7o3RHdm12f3n/WY6zzt47e0RzJM49Tqh6EL+E2WIZiXHctXH5+vwQ+xC5RP5F8ReClIHoEWaLlVyZ7GTttL7PegAY220sACRXJAtSCaJEmC3WFe2VMV3HCNI1sgxhgmUtsTYSoyBdI8sQJljDFcNPV51+5E0to52TO2dv+V4hKkI8kwjyIEwC5OXrL/ey7vVGzzfURnU3abeu0q6bijel3Etxl7tne2crpArLV4V4ZLV69WrL9yoBSYh9CEggU5upkCr+0eMfjtaOQ22HZtVmZdVmySSy5+2et3xViEfCbLGa8nv17+OujrOR2mR5Z/WT9xO6HGQ+sVx5Z/l39Z9qP1XLaKMKo4SuBXEiri0WABQYCrwue2kZ7W+DfgvoFiB0OchM4tpiAUBfWd9lLssIkMUFixlghC4HmUl0wQKAFS4r+sn7pdek7yrdJXQtyExiDJZCqljnug4AogqjKk2VQpeDzCHGYAFAiEOIf1f/YmPxhoINQteCzCHSYElA8oXbFxNuTNj67Nbr168LXQ5qM5EGCwBG2o7sf6R/RVHFsmXLhK4FtZnoLjc0pFarvby8Kisrjx49GhQUJHQ5qA3Eu8UCABcXl6ioKACIiIgwGAxCl4PaQNTBAoCIiAhPT8+srKy4OBy13J6IelfISk5Ofv311+3t7a9du+bk5CR0OahVxL7FAoDXXnstKCiovLx8zZo1QtdCjckER47Ali3wyy9gNAIAXLkCaWkPvpCYCCaTUNWZoR1ssQDgypUrw4cPZxgmPT396aefFrocvun1MHEiPPUU+PvDH39ARgacOgVxcVBSAmvX1n3H2Rlyc0HRboaptYMtFgB4e3u/8847JpMpPDxc6Foo2LUL+vWD//0PZs6EbdtgyBCIjxe6Jq7axxYLAEpLSz08PLRarY2NjVTKw/8PSUlJo0ePtre3594UV//5D0yYADNm1L3cuxd+/hlGjoRjxyA4uO7NyEgoLm5HWyzBJqy2lUKhkMvlDMNoNBpeGgwODl64cGFsbCwvrXFiMIB1g38IuRx0OgAAmQxsbevelEgEKIyDdhOs9evX3717d9iwYSdPnuS+xcrOzh4/fvzWrVvnzJkzZMgQXio0n7c3pKbCW2/VvVQqwccHAGDoUJg1q+7N5csFKc18pD3Iz8+3tbWVSCQpKSl8tblgwQIACAwM5KtB85WVEQ8PkpBAcnLId9+RAQNIcTGJjSUffvjgO716kZoa4Upss/YRrGnTpgFASEgIj22WlpY6OjoCwM8//8xjs+aoqSFFRSQqirz5JlmxghQWEkLIyZPkp58efGfpUqLXC1WgGdpBsM6dOyeRSBQKxa1btxq+P2zYsLZunjds2NCwhU2bNgGAh4dHbW2tZX+nBi5eJL16kbg4wQqgQ+yXGxiGWbx4MSEkMjKyX7+H5u2Qtp/PPvIjixYtGjJkyI0bN7788kuuhZqHEFiyBO7ehZs3hSmAHoGD3ZL4+HgA6Nu377179xp/yrRR4xaOHz8OAHZ2drdv36b/2zSyZw8BIC4upKJCgN5pEnWwNBpN7969ASApKYleL8HBwQAwZ84cel08Xk0NcXcnAGTnTkt3TZ+og8UO8fP393/sxoYv169f79Kli1QqvXjxIr1eHmPVKgJAfH2JyWTRfi1CvMGq//e+cOEC7b6WLl1qgQQ/JC+P2NoSiYTwdwFFVMQbLEvuoSyzz33I1KkEgEyfbqHuLE6kwbL8MXXzZwk8O3eOSCREoSAPX0DpSMQYLIPBwN5meeSyE1Umk2nkyJEAsGbNGtodpfzrX8TGhqxeTbUjYYkxWOyNYctft2zqSiy/vv76awB465lnSHU1vV4EJ7pg1d9pOXTokOV7nzp1KgBMp3boI8DBnEBEFyxh7w3n5eXxfre7IQFOPwUirmBlZmZaW1tbW1v//fffQtWwatUqAPD19TXxfXlJsAtmQmguWFVVD/6s15OGBzxGIykvf/CyspKfi3wvvfQSALA3B4VSU1PD3pTcyfcFccEu8QuhuWA5Oz84vty+nYSHP/goPZ0AkBMn6l4OH07y8riWsn//fgBwcHAoKSnh2hY33333HQC4uLhU8HcLT+CbkhZn/uiGwYMhIqJuDC13er1+xYoVALB27Vr24F1AISEhAQEBarX6k08+4aVBo9EYEREBAKtWrXriiSd4aVPkWhiaXFJSN37/3r1HP3J3hxEjICYGoqMBAG7ehM8/b64pJ6czJSUHmvpUqVSqVKohQ4bMmzevNXVTJZFIPvvsszFjxnz++efFxcU9evTg2GBGRkZmZqanp2dYWBgvFYpfC8F65x1gx5fn50Ng4KOffvAB+PrC9OkAAIWF0Py8hPHjS1JSmvuGg4PD5MmTrRtMK6iqqjIYDA4ODs0XyYvc3NyG471GjRrl4eGh1+u/+eYbXtp3cnIKDg6Wy+W8tCZ+zU3/cnGBnJy6eSI7dkBmJmzaVPdRRgasWAFHj8KBA7BrF+Tnw1dfwfnzzfVkZ5daVZXS1Kfnz5/ft2+fm5tbdna2ra0tAJw4cSI0NHTSpEnbt2835zdri8rKSi8vr8GDBx84cICdEHbq1KnAwEBbW9vly5d3796dY/tKpTIxMdHFxeXatWvcW2sfmjn+anzwrtWSS5eITkfS00lQUN1HL79MbG25HrybTCY/Pz8AWLt2LfuOgKMbjEYjO986JiaGl/YZhhk7diwAvP/++7w0KH7NBWvQoAcTQ779lkRFkYULya5dJCSE/PUXeeONuo+uXyfOzqSggGspZ86ckUgktra2ubm57DtCjcfavHkzAAwYMIDHe0pKpVIqlcrl8mvXrvHVppiZc4F08mTey6gzZcoUAJgxYwb7UqPRsOdQ33//Pa0uG11eKisrY09Lk5OT+e1o5syZADCZ3l+fmLQ5WAkJZM8eGpUQ0uCOypkzZ9h32Fu29EazNL68tHDhQgB44YUXeO/rzp077AHWsWPHeG9cbNoQLIYh69aR+HhSVkavHvLhhx8CwIgRI9g7KiaTadSoUQAQHR3Ne1+Nx+dcvnzZ2traysrqr7/+4r07QsjHH38MAN7e3gaDgUb74tGGYFVVkbg4EhdH4uPp1UOqq6vd3d0BYNeuXew79EazNB6fw650umjRIn47qqfT6QYOHAgA27Zto9SFSIjrJjRr9+7dAODi4lJZWcm+Y5mZ0AcPHgQAe3v7u3fv8tjRI3788UcQx50rqsQYLIZhxo0bBwBRUVHsO/n5+V27dgWA3377ja9eHhmfo9PpPD09AeDLL7/kq4umiOFeO21iDBZ53Ml5dHQ08DeapfH4HPa2oLe3t57+EgliGB1Em0iDRQh5++23AeD1119nX9aPZtm+fTv3xh/ZZtSfrx09epR7460horVu6BBvsBqfnCcmJgKAs7Mzx9EsjcfnzJ49GwBeffVVrkW3mojWuqFDvMEijzs5DwgIAIDly5eb3Wb9sVT9eVlqaiq727169SoPRbeaKNa6oUbUwaoPwdatW9l30tLSOIbgkbAyDMOGNTIykre6W0eQWW4WI+pgkcfttv79738DwLJly8xoTa/XswdqJ+4Pft2zZw/wPVi09TrwsFKxB4sQMnHiRAAICwtjXxYVFSUkJJh9W7q0tDT+/hXempoa9mIs78PbW6+jDoRvB8Fib7PQODlfuXJlw9tHguioU3faQbAInZNz2lMIW4/HyYaHDpFFiwjbjEZDFi8mf/5JYmMffOG990hBAdHryf0bZrS0j2DRmB5Ne9Jz6/E4PXrDBtKjB9mxgxBC7t4lXl7k4EFyfxQSIYSMHElOnyabNpGgILJvH8femtM+1nl3cHBYuXJleHh4WFiYi4sL95HjGRkZ+/btUygU69at46VCLuzs7D766KN58+ZFRES4u7srmn78hFQ6iGFsm/qUnS0wfz7ExMArrzTZnZMTzJwJt2/DpEmcym4BxdDySq/Xu7q68vhYue7du68WzXovJpPJ19e3xZlhPj6/A5Cm/rO3Jxs2kE8/JVu2kNmzH2yxXF3Jyy/X/dejB8nKIiYTuXSJ7m/UPrZYAHDnzp3y8nKdTvfUU0916dKFe4M7d+4cPHgw93Z4IZVKDx8+/Msvv2zdurWZr7m7d7Vu+l+sfpbaggXg7w9nz9a9HDsWtm2r+/NLL7HdwdChnItuVrsJVmRkpFarnTZtWlJSktC1UOHq6jp37ty5c+dyaWTjRgAAqRQ2b37wtJQuXaB+Q99MLvkl9nXeWefPn09KSlIoFDExMULX0j6MHg0BAY//6OZNWLIEZs+GGzcoFtAOHivHMMyYMWMuXrwYHR29evVqocsRtatXAQC8vAAAKirgyBEwmcDHB3x9675w5gz07Qu9e0NGBqSkQGQktVLoHsLxgZ2waqHVQTuQwkLSvTvp1u3xM/PWrCHnz1PsnYctVlZNzR61mv1zL5ksvG9frmFvoKqqysvLq6ioKDExMSQkhMeWO4MpU2D/fggNhd27H3r/q6/AwQGmTaPZN/dsni4vX3r9+i2t9pZWW8j3CJD33nsPAJ599tkOvwQeDbm5dYvJ359NRwgh+/aRf/6TREaSgwcpds1PsFbl5HBvpzFLzrLvqD74gAAQPz9LP/6Cn7PCPzWahSrVQpXqSFkZLw2ylixZotPpZs2axU4tRGZ4/31wd4fUVNizh7c2tVrt+vXr36p/JOxjcc/m6fLyqBs3ygyGMoNBazKVGwzX+XgW6IkTJ6CDjlWysN276x4xdn82nfkYhklKSmLHGgFAampqU9/kf1f4cW7uKKVyZU5OGYfJvgaDgV3vZf369dwr7OQYhowdSwAIx6Vu0tLSxo8fz0bK19e3+al4/AdrY17e6NRUP6VyQkbGD2q10ayDbna9l446HtzylEoilRK5nJi31E1JSUlYWJiVlRUAODo6xsbGGo3G5n+Eh2AV6/WZD19huqXVhqlUfkqln1I5OTPzbBtH/dav9/JTw4ciI25mzWLGj88MDQ1v+asN6PX62NhYdrFMmUwWFhbWyjHcFC+Q/llZOSUzk43XgmvXbmi1rfxBeuu9dGaFhbe7desGACdPnmzljxw/ftzb25vd97344ouZmZmt747ulXcdwyQUFQWkp/splWNSU78oKKhq6cCL9novnRk7Q8nHx6fFtW6ys7Mn3R+uNWjQoMOHD7e1L0vc0qkwGDbk5Y1KTQ1MSxv49NPN76HZqRPvvvuuBQrrbGpra1tc66asrCwyMpIdStmzZ8+YmBidTmdGX5a7V3i5uvrd+8vU+vn5nT17tvF3Dhw4AAD29vYdeyUWATWz1o3JZEpISHB2dgYAqVQaGhqqVqvN7sjSN6EPHTrUv39/Nl7BwcE5DU4n66enbtmyxcJVdSqPXevm1KlTQ++P/ZswYcIlzgNMBRjdUF1dHRMTwx5IKhSKyMjIqqoq0mC9lw6/2p2wHlnrJi8vLzQ0lI2Um5tbQkICL70INmymoKAgNDRUIpEAQJ8+fTZv3mzh9V46s/nz57NbpujoaBsbGwDo2rVrdHS0ttVn7i0SeDxWSkrKiBEj6u8vPf/888LW00mo1Wp2ITsAkEgkb7/9dmFhIb9dCD/Qz2QyrV69WiKRWFlZSSSS0NDQoqIioYvqyC5cuODv7w8ANjY2NjY2p0+fptGL8GPeJRIJe8nOz89PJpN9++23Xl5eGzdu1Ov1QpfW0RQWFs6YMeOZZ575/fff+/Tp4+TkVFtbq1QqqXRGI61t0nC9F5VK9eabb7KFDRw4cO/evUJX10HodLrY2Fg7OzsAkMvlYWFhGo2mfq0bGrsIgYP12PVeTpw4wS4cBQCBgYF4CZ6jQ4cOPfnkk+zfZ3Bw8M2bN+s/Yi+vz507l/dOBQ5WUw9gZu99sg/ikslky6KiKlu6nY4aS09Prx/oMnjw4MZn3CqVitJaN0IGq8X1XkpLS8PCwqytrd/avXtCRkaiuYNwOiH2r44d6OLg4NDMbTQe17ppSMhgtXK9l0uXLr2bnc2Okph2+fIFjcYy5bVT7Ma+Z8+ecH+gS3nD58I3Ur/WzQ8//MBjGYIFq60PMvmtouKVv/9m4xWuUuXjAMDHOX78uI+PD7vva/1Al7i4OABwc3Orrn8+JWfCBMtEyJJjxxzd3du03oueYRLV6vHp6X5K5TOpqRvy8u7hgdd9V69eZVedBABPT882rfJtMplGjhwJAGvWrOGrHmGm2CeXlPw3N9dDLv/Gw4N9UG/rlRgM8bdvJ5eUMABOMtk8V9e82trTFRV2VlYA8IK9/ezevelULVIVFRUxMTGxsbE6na5nz54rVqwIDw9v64I8586dCwgIsLGxycrKavhsbPPxldDWqzYaJ1665KdUHuPwfLrMe/dmZWX5KZX+aWkf5eQc6pTDbBoPdLlz547ZrfG7xKEAwdqUn++nVM7OzuZ4EsIQ8ktp6Xdq9ca8vP3FxdUmU7WAi9RaXF5e3rBhw9itw3PPPZeens69QR4XZbX0LZ18nW5vcbEUYJmbm4RbUxKA/3NwmO7sDAB7iovDVKowleqGVstLneLn6urKMEzfvn0TEhJ+/fXX4cOHc2zQzc1t6dKlhJDw8HCGYbjWxz2bbbJYpfJTKv/L6yMtN+bldc5doUqlquFjbnA9Hhe+t+gW64JGc7ay0tbKar6rqyX77agGDhzYzEq4Zqhf7TcqKqqyspJLU5YLlomQzwoKAGDuE084ymQW6xe1yfTp0wMCAtRqNTug12yWu9yQVFy8MT/fvUuXH3x8ZBKOx1cPYQAkAHy22LmlpaWNGjXK2to6MzOTnYVgBsttsQLt7Sc5Oka4ufGbKgCQYqp4NWLEiJkzZ+r1+uXLl5vdCN0tlrKqalVOjoNMBgBOMlnswIH0+kI8UqvVgwYN0mg0R48eDQoKMqcJHs4lmna+sjLyxg2qXSBKOD4km/qukACYCDERwvnCCLKoJUuWeHp6XrlyJT4+3owfpx6sixrN7Ozs2dnZ++/epd0X4pFcLv/000/9/f3HjBljxo/TPcb6Q6NJLimJGTCAXheIKkKIxKyTLeFn6SAxMy9VgMFClNDdFTKEGAmRSzG+nU47eJYOao9wW4KowGAhKjBYiAoMFqICg4WowGAhKjBYiAoMFqICg4WowGAhKjBYiAoMFqICg4WowGAhKjBYiAoMFqICg4WowGAhKjBYiAoMFqICg4WowGAhKjBYiAoMFqICg4WowGAhKjBYiAoMFqICg4WowGAhKjBYiAoMFqICg4WowGAhKjBYiAoMFqICg4WowGAhKjBYiAoMFqICg4Wo+H+zwZ0gDhLJ6gAAASh6VFh0cmRraXRQS0wgcmRraXQgMjAyMS4wMy41AAB4nF1PsU7DMBQ8u6kdxylpISprxICY4QPiperEypzRYkCsbMwMSCyImQGx8AuNfwEmJnakSkh8AXZsE8OTnu7e+fTe+Wvz8gFbpW0CX3Xoa8LQOX3C0FjMxtEjb44d0vBAqccJYerIYcaUdpgK/zEYFsMFwjHMhIaLwst/IffnibSJCbU5QDJkU0wZGAfPNc1FJwpNC9nJUlM5Q7HTiArVHNUC1S7YHkre1YTxUhYi348/R63vPtXN7bb3o1Gr9aFx7OHi3vIz4/V3tTy/CvxZPa6egv8y4Urht0w7ctUmnn7kpk88Tm8Tfxs9Nk/Yq0yyv485gbmJ2V4PTkz8y/fb6WbMP+Qcdi5/AAGMRoNw5pmLAAABPHpUWHRNT0wgcmRraXQgMjAyMS4wMy41AAB4nK2VS27EIAyG95zCFxiETRhgPZm2UtWp1EXvUKnL3l+1SeJBytDmFaHIP48vvxNMDMj10b9+/YBe1BsD5KTB45Zzhk9yzhmZHy3lzN1wQpu6hNLnLI86uEALUbdCOQ8rmEI25K2UzkaHheKt3+ElBjdSUo4bKcHSSMHpDU2U25zSNShevcwoK7z46e1OazdR0IYDKO6IjE7HUA7J6O4F9nyjQyhVRvM6+l5M+WO/PNi7/3rZU9O8llrV+LSGElun1AqKs9Q6X5ZT7jU9/9LvSyn8aCp3ERz5WnS1CCo4OqvgKKrgKKngKA8HkpFI8h0ER4gqEJBUEKCvhTqQaepAAOqAI4y1SLXIlTf5E40jvtgrz3kDuLw8lxHJDFB6rrfe/AITyA4A6wMF9QAAAK16VFh0U01JTEVTIHJka2l0IDIwMjEuMDMuNQAAeJxVTkEOwyAM+8qOoEEEoQxQj5GqnboHTDtx3RP6+CUtrTIpkWIntkNkyHK91yfeP0TmZXvs3ZBZLNdiu1m56cv0bTMFsDXnI9SpRjc/nEfITcYJSojOJ0jHBkoWVFthlAGzqEQ8p311AhcGM4gIWaigj/w/kpMrlwdUSQyL/pClqP/yw9/vwYex9j1t1cJuP4TAO/rlD+xTAAAAAElFTkSuQmCC\" alt=\"Mol\"/></td>\n",
       "      <td><img data-content=\"rdkit/molecule\" src=\"data:image/png;base64,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\" alt=\"Mol\"/></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     pKa marvin_pKa marvin_atom marvin_pKa_type original_dataset      ID  \\\n",
       "536  9.7       9.63           4           basic     ['chembl25']  871123   \n",
       "\n",
       "                                           smiles  \\\n",
       "536  CC(C)(C)[NH2+]CC(O)c1cc(Cl)c(N)c(C(F)(F)F)c1   \n",
       "\n",
       "                                            protonated  \\\n",
       "536  <img data-content=\"rdkit/molecule\" src=\"data:i...   \n",
       "\n",
       "                                          deprotonated  \n",
       "536  <img data-content=\"rdkit/molecule\" src=\"data:i...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# make sure the directory for saving the run data exists \n",
    "# run_data stores pickle files of the dicts containing dataset-Dataframes, morgan fingerprints and pyG graphs)\n",
    "run_filename = \"run_data\"\n",
    "os.makedirs(f\"{run_filename}/\", exist_ok=True)\n",
    "\n",
    "# check if saved dictonary of dataset-Dataframes is available and if so, import it\n",
    "if os.path.isfile(f\"{run_filename}/dataset_dfs.pkl\"):\n",
    "    print(\"Loading data ...\")\n",
    "    with open(f\"{run_filename}/dataset_dfs.pkl\", \"rb\") as pickle_file:\n",
    "        dataset_dfs = pickle.load(pickle_file)\n",
    "\n",
    "# create DataFrames for each dataset, store them in a dictonary and save it as as .pkl file in in the run_data folder\n",
    "else:\n",
    "    print(\"Generating data ...\")\n",
    "    sdf_paths = load_data(\"../../data/Baltruschat/\")\n",
    "    dataset_dfs = preprocess_all(sdf_paths) # load all datasets in Dataframes and calculate protonated and deprotonated conjugates\n",
    "    dataset_dfs[\"train_split\"], dataset_dfs[\"val_split\"] = train_validation_set_split(\n",
    "        dataset_dfs[\"Training\"], TRAIN_SIZE, SEED\n",
    "    ) # take a copy of the \"Training\" dataset, shuffle and split it into train and validation datasets and store them as Dataframe in respective dict   \n",
    "\n",
    "    with open(f\"{run_filename}/dataset_dfs.pkl\", \"wb\") as pickle_file:\n",
    "        pickle.dump(dataset_dfs, pickle_file)\n",
    "\n",
    "# notification\n",
    "print(dataset_dfs.keys())\n",
    "display(dataset_dfs[\"train_split\"].head(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Calulate fingerprint based data**\n",
    "Create Fingerprints, target-value objects and add best tanimoto similarities of fps form external validation set molecules with those of the train molecules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fp_data keys: dict_keys(['Training', 'Novartis', 'Literature', 'train_split', 'val_split'])\n",
      "calculated/loaded fingerprint data successfully\n"
     ]
    }
   ],
   "source": [
    "# check if saved dictonary of fingerprint data is available and if so, import it\n",
    "if os.path.isfile(f\"{run_filename}/fp_data.pkl\"):\n",
    "    with open(f\"{run_filename}/fp_data.pkl\", \"rb\") as pickle_file:\n",
    "        fp_data = pickle.load(pickle_file)\n",
    "\n",
    "# create fingerprint arrays (dim: num molecules x fp bits) for each dataset, store them in a dictonary and save it as as .pkl file in in the run_data folder\n",
    "else:\n",
    "    fp_data = {}\n",
    "    for name, df in dataset_dfs.items():\n",
    "        X_feat, y = make_stat_variables(df, [], [\"pKa\"])\n",
    "        X_prot = generate_morgan_fp_array(\n",
    "            df, \"protonated\", nBits=FP_BITS, radius=FP_RADIUS, useFeatures=True\n",
    "        )\n",
    "        X_deprot = generate_morgan_fp_array(\n",
    "            df, \"deprotonated\", nBits=FP_BITS, radius=FP_RADIUS, useFeatures=True\n",
    "        )\n",
    "        X = np.concatenate((X_prot, X_deprot), axis=1)\n",
    "        fp_data[f\"{name}\"] = {\"prot\": X_prot, \"deprot\": X_deprot, \"pair\": X, \"y\": y}\n",
    "\n",
    "    with open(f\"{run_filename}/fp_data.pkl\", \"wb\") as f:\n",
    "        pickle.dump(fp_data, f)\n",
    "\n",
    "# add max tanimotosimilarity to the Dataframes of external test sets\n",
    "    train_name = \"train_split\"\n",
    "    val_name = \"val_split\"\n",
    "    for name, dataset in fp_data.items():\n",
    "        if name in [train_name, val_name]:\n",
    "            pass\n",
    "        else:\n",
    "            print(f\"calculating similarities for {name}\")\n",
    "            max_scores = []\n",
    "            for test_mol in dataset[\"prot\"]:\n",
    "                scores = []\n",
    "                for ref_mol in fp_data[train_name][\"prot\"]:\n",
    "                    scores.append(calculate_tanimoto_coefficient(test_mol, ref_mol))\n",
    "                max_scores.append(max(scores))\n",
    "            dataset_dfs[name][\"Similarity_max\"] = max_scores\n",
    "\n",
    "with open(f\"{run_filename}/dataset_dfs.pkl\", \"wb\") as f:\n",
    "    pickle.dump(dataset_dfs, f)\n",
    "\n",
    "# notification\n",
    "print(\"fp_data keys:\", fp_data.keys())\n",
    "print(f\"calculated/loaded fingerprint data successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Calculate graph data**\n",
    "Create graph data with node and edge features specified in the config file and prepare loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating data ...\n",
      "Generating data for: Training\n",
      "Generating data with paired boolean set to: True\n",
      "Generating data for: Novartis\n",
      "Generating data with paired boolean set to: True\n",
      "Generating data for: Literature\n",
      "Generating data with paired boolean set to: True\n",
      "Generating data for: train_split\n",
      "Generating data with paired boolean set to: True\n",
      "Generating data for: val_split\n",
      "Generating data with paired boolean set to: True\n",
      "graph_data keys: dict_keys(['Training', 'Novartis', 'Literature', 'train_split', 'val_split'])\n",
      "Generating loader for Training\n",
      "Skipping unsplit Training dataset\n",
      "Generating loader for Novartis\n",
      "Generating loader for Literature\n",
      "Generating loader for train_split\n",
      "Generating loader for val_split\n",
      "loaders keys: dict_keys(['Novartis', 'Literature', 'train_split', 'val_split'])\n",
      "calculated/loaded graph data successfully\n"
     ]
    }
   ],
   "source": [
    "# check if saved dictonary of graph data is available and if so, import it\n",
    "if os.path.isfile(f\"{run_filename}/graph_data.pkl\"):\n",
    "    print(\"Loading data ...\")\n",
    "    with open(f\"{run_filename}/graph_data.pkl\", \"rb\") as f:\n",
    "        graph_data = pickle.load(f)\n",
    "\n",
    "# create list of 'PairData' graph objects for each dataset, store them in a dictonary and save it as as .pkl file in in the run_data folder\n",
    "else:\n",
    "    print(\"Generating data ...\")\n",
    "    graph_data = {}\n",
    "    for name, df in dataset_dfs.items():\n",
    "        print(f\"Generating data for: {name}\")\n",
    "        graph_data[name] = make_pyg_dataset_from_dataframe(\n",
    "            df, list_node_features, list_edge_features, paired=True\n",
    "        )\n",
    "    with open(f\"{run_filename}/graph_data.pkl\", \"wb\") as f:\n",
    "        pickle.dump(graph_data, f)\n",
    "\n",
    "print(\"graph_data keys:\", graph_data.keys())\n",
    "\n",
    "# create an iterable loader object from the list of graph data of each dataset and store them in a dictonary\n",
    "loaders = {}\n",
    "for name, dataset in graph_data.items():\n",
    "    print(f\"Generating loader for {name}\")\n",
    "    if name == \"Training\":\n",
    "        print(\"Skipping unsplit Training dataset\")\n",
    "        continue\n",
    "    elif name == \"train_split\" or name == \"val_split\":\n",
    "        loaders[name] = dataset_to_dataloader(dataset, BATCH_SIZE, shuffle=True) # Shuffling is essential to avoid overfitting on particular batches\n",
    "    else:\n",
    "        loaders[name] = dataset_to_dataloader(dataset, BATCH_SIZE, shuffle=False) # Testsets must not be shuffled in order to be able to calculate per datapoint predcitons with all graph and baselinemodels in the analysis part\n",
    "\n",
    "# notification\n",
    "print(\"loaders keys:\", loaders.keys())\n",
    "print(f\"calculated/loaded graph data successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_node_features = next(iter(graph_data['Novartis'])).x_p.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**show feature value range**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_43636/1145483844.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mentry\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx_p\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m             \u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx_d\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# print all possible node feature values\n",
    "values = [set() for i in range(len(list_node_features))]\n",
    "for dataset in graph_data.values():\n",
    "    for entry in dataset:\n",
    "        for i, row in enumerate(entry.x_p.cpu().T):\n",
    "            values[i] = values[i] | set(row.numpy())\n",
    "        for i, row in enumerate(entry.x_d.cpu().T):\n",
    "            values[i] = values[i] | set(row.numpy())\n",
    "print(\"Node features:\")\n",
    "for name, values in zip(list_node_features, values):\n",
    "    x = list(values)\n",
    "    x.sort()\n",
    "    print(f\"{name}:{x}\")\n",
    "print(\"\\n\")\n",
    "\n",
    "# print all possible edge feature values\n",
    "values = [set() for i in range(len(list_edge_features))]\n",
    "for dataset in graph_data.values():\n",
    "    for entry in dataset:\n",
    "        for i, row in enumerate(entry.edge_attr_p.cpu().T):\n",
    "            values[i] = values[i] | set(row.numpy())\n",
    "        for i, row in enumerate(entry.edge_attr_d.cpu().T):\n",
    "            values[i] = values[i] | set(row.numpy())\n",
    "print(\"Edge features:\")\n",
    "for name, values in zip(list_edge_features, values):\n",
    "    x = list(values)\n",
    "    x.sort()\n",
    "    print(f\"{name}:{x}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Training of predictive models**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **train baseline models**\n",
    "train all baseline models in protonated, deprotonated and pair mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trained/loaded baseline models successfully\n"
     ]
    }
   ],
   "source": [
    "models_dict = {\n",
    "    \"RFR\": RandomForestRegressor(\n",
    "        n_estimators=NUM_ESTIMATORS, random_state=SEED\n",
    "    ),  # Baltruschat n_estimatores = 1000\n",
    "    \"PLS\": PLSRegression(),\n",
    "}\n",
    "\n",
    "baseline_models = {}\n",
    "train_name = \"train_split\"\n",
    "val_name = \"val_split\"\n",
    "\n",
    "for model_name, model_template in models_dict.items():\n",
    "    baseline_models[model_name] = {}\n",
    "    for mode, X in fp_data[train_name].items():\n",
    "        if mode == \"y\":\n",
    "            continue\n",
    "        path = f\"models/baseline/{model_name}/{mode}/\"\n",
    "        if os.path.isfile(path + \"model.pkl\"):\n",
    "            with open(path + \"model.pkl\", \"rb\") as pickle_file:\n",
    "                baseline_models[model_name][mode] = pickle.load(pickle_file)\n",
    "        else:\n",
    "            print(f\"Training {model_name}_{mode}...\")\n",
    "            y = fp_data[train_name][\"y\"]\n",
    "            y_val = fp_data[val_name][\"y\"]\n",
    "            model = copy.deepcopy(model_template)\n",
    "            model.fit(X, y)\n",
    "            print(f\"{model_name}_{mode}: {model.score(fp_data[val_name][mode], y_val)}\")\n",
    "            baseline_models[model_name][mode] = model\n",
    "            os.makedirs(path, exist_ok=True)\n",
    "            with open(path + \"model.pkl\", \"wb\") as pickle_file:\n",
    "                pickle.dump(model, pickle_file)\n",
    "print(f\"trained/loaded baseline models successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Train graph models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_node_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Training**\n",
    "train all graph models in protonated, deprotonated and pair mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention pooling: False\n",
      "0\n",
      "Number of parameters:  38502\n",
      "Training GCNPairSingleConv at epoch 0 ...\n",
      "LR: 0.001\n",
      "GCNPairSingleConv\n",
      "GCNPairSingleConv(\n",
      "  (pool): GlobalAttention(gate_nn=Sequential(\n",
      "    (0): Linear(in_features=9, out_features=9, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=9, out_features=1, bias=True)\n",
      "  ), nn=None)\n",
      "  (convs): ModuleList(\n",
      "    (0): GCNConv(9, 96)\n",
      "    (1): GCNConv(96, 96)\n",
      "    (2): GCNConv(96, 96)\n",
      "  )\n",
      "  (lins_d): ModuleList(\n",
      "    (0): Linear(in_features=96, out_features=96, bias=True)\n",
      "    (1): Linear(in_features=96, out_features=1, bias=True)\n",
      "  )\n",
      "  (lins_p): ModuleList(\n",
      "    (0): Linear(in_features=96, out_features=96, bias=True)\n",
      "    (1): Linear(in_features=96, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "Training on cuda.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   0%|          | 0/4001 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (1151x35 and 9x96)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_43636/678930308.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Training on {DEVICE}.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         results = gcn_full_training(\n\u001b[0m\u001b[1;32m     41\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0mloaders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"train_split\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/shared/projects/pKa-prediction/anaconda3/envs/pkasolver/lib/python3.9/site-packages/pkasolver-0.1+52.g0f70ae6.dirty-py3.9.egg/pkasolver/ml_architecture.py\u001b[0m in \u001b[0;36mgcn_full_training\u001b[0;34m(model, train_loader, val_loader, optimizer, path, NUM_EPOCHS)\u001b[0m\n\u001b[1;32m    709\u001b[0m             \u001b[0mgcn_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m20\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 711\u001b[0;31m             \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgcn_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    712\u001b[0m             \u001b[0mval_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgcn_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    713\u001b[0m             pbar.set_description(\n",
      "\u001b[0;32m/data/shared/projects/pKa-prediction/anaconda3/envs/pkasolver/lib/python3.9/site-packages/pkasolver-0.1+52.g0f70ae6.dirty-py3.9.egg/pkasolver/ml_architecture.py\u001b[0m in \u001b[0;36mgcn_test\u001b[0;34m(model, loader)\u001b[0m\n\u001b[1;32m    662\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    663\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Iterate in batches over the training dataset.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 664\u001b[0;31m         out = model(\n\u001b[0m\u001b[1;32m    665\u001b[0m             \u001b[0mx_p\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx_p\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m             \u001b[0mx_d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx_d\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/shared/projects/pKa-prediction/anaconda3/envs/pkasolver/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/shared/projects/pKa-prediction/anaconda3/envs/pkasolver/lib/python3.9/site-packages/pkasolver-0.1+52.g0f70ae6.dirty-py3.9.egg/pkasolver/ml_architecture.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x_p, x_d, edge_attr_p, edge_attr_d, data)\u001b[0m\n\u001b[1;32m    610\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    611\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_p\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_attr_p\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_attr_d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 612\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_p\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_attr_p\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_attr_d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    613\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/shared/projects/pKa-prediction/anaconda3/envs/pkasolver/lib/python3.9/site-packages/pkasolver-0.1+52.g0f70ae6.dirty-py3.9.egg/pkasolver/ml_architecture.py\u001b[0m in \u001b[0;36m_forward\u001b[0;34m(self, x_p, x_d, edge_attr_p, edge_attr_d, data)\u001b[0m\n\u001b[1;32m    180\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlins_p\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m                 \u001b[0mx_p\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_p\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medge_index_p\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m                 \u001b[0mx_p\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_p\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medge_index_p\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/shared/projects/pKa-prediction/anaconda3/envs/pkasolver/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/shared/projects/pKa-prediction/anaconda3/envs/pkasolver/lib/python3.9/site-packages/torch_geometric/nn/conv/gcn_conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, edge_index, edge_weight)\u001b[0m\n\u001b[1;32m    179\u001b[0m                     \u001b[0medge_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m         \u001b[0;31m# propagate_type: (x: Tensor, edge_weight: OptTensor)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/shared/projects/pKa-prediction/anaconda3/envs/pkasolver/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/shared/projects/pKa-prediction/anaconda3/envs/pkasolver/lib/python3.9/site-packages/torch_geometric/nn/dense/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/shared/projects/pKa-prediction/anaconda3/envs/pkasolver/lib/python3.9/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1845\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhas_torch_function_variadic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1846\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1847\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1848\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (1151x35 and 9x96)"
     ]
    }
   ],
   "source": [
    "models = [('GCNPairSingleConv', GCNPairSingleConv), \n",
    "('GCNPairTwoConv', GCNPairTwoConv), \n",
    "('GCNProt', GCNProt), \n",
    "('GCNDeprot', GCNDeprot), \n",
    "('NNConvPair', NNConvPair), \n",
    "('NNConvDeprot', NNConvDeprot), \n",
    "('NNConvProt', NNConvProt )]\n",
    "\n",
    "for model_name, model_class in models:\n",
    "    path = f\"models/gcn/\"\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "    pkl_file_name = f\"{path}/{model_name}.pkl\"\n",
    "    if os.path.isfile(pkl_file_name):\n",
    "        print('Attention: RELOADING model')\n",
    "        with open(pkl_file_name, \"rb\") as pickle_file:\n",
    "            model = pickle.load(pickle_file)\n",
    "    else:\n",
    "        model = model_class(num_node_features, num_edge_features)\n",
    "\n",
    "    if model.checkpoint[\"epoch\"] < NUM_EPOCHS:\n",
    "        model.to(device=DEVICE)\n",
    "        print(model.checkpoint[\"epoch\"])\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "        print(\"Number of parameters: \", sum(p.numel() for p in model.parameters()))            \n",
    "        try:\n",
    "            optimizer.load_state_dict(model.checkpoint[\"optimizer_state\"])\n",
    "        except:\n",
    "            pass\n",
    "        scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "            optimizer, patience=5, verbose=True\n",
    "        )\n",
    "\n",
    "        print(\n",
    "            f'Training {model_name} at epoch {model.checkpoint[\"epoch\"]} ...'\n",
    "        )\n",
    "        print(f'LR: {LEARNING_RATE}')\n",
    "        print(model_name)\n",
    "        print(model)\n",
    "        print(f'Training on {DEVICE}.')\n",
    "        results = gcn_full_training(\n",
    "            model.to(device=DEVICE),\n",
    "            loaders[\"train_split\"],\n",
    "            loaders[\"val_split\"],\n",
    "            optimizer,\n",
    "            pkl_file_name,\n",
    "            NUM_EPOCHS,\n",
    "        )\n",
    "\n",
    "        plot_results(results, f'{model_name}')\n",
    "        with open(f\"{path}/{model_name}.pkl\", \"wb\") as pickle_file:\n",
    "            pickle.dump(model.to(device='cpu'), pickle_file)\n",
    "print(f\"trained/loaded gcn models successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_models = {}\n",
    "for model_name, model_class in models:\n",
    "    path = f\"models/gcn/\"\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "    pkl_file_name = f\"{path}/{model_name}.pkl\"\n",
    "    if os.path.isfile(pkl_file_name):\n",
    "        with open(pkl_file_name, 'rb') as pickle_file:\n",
    "            model = pickle.load(pickle_file)\n",
    "        model.to(device='cpu')\n",
    "        best_loss = max([x for x in model.checkpoint['best_states'].keys() if x < 4_000]) \n",
    "        model.load_state_dict(model.checkpoint['best_states'][best_loss][1])\n",
    "        loss = model.checkpoint['best_states'][best_loss][0]\n",
    "        print(f'{model_name},Epoch {best_loss}, Loss:{loss}')\n",
    "        graph_models[model_name] = model\n",
    "    else:\n",
    "        print(f'{path} not found')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predictions of baseline and graph models\n",
    "\n",
    "for i,dataset_name in enumerate(['Novartis', 'Literature', 'val_split']):\n",
    "\n",
    "    df_ml = test_ml_model(baseline_models, fp_data[dataset_name], fp_data[dataset_name]['y'],dataset_name)\n",
    "    df_gcn = test_graph_model(graph_models, loaders[dataset_name], dataset_name)\n",
    "    df= pd.concat([df_ml.drop(columns=['Dataset', 'pKa_true']), df_gcn],axis=1)\n",
    "    df= pd.concat([df_gcn],axis=1)\n",
    "    torch.cuda.empty_cache()\n",
    "    if i == 0:\n",
    "        df_res = df\n",
    "    else:\n",
    "        df_res = pd.concat([df_res,df])\n",
    "display(df_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raise RuntimeError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predictions of baseline and graph models\n",
    "\n",
    "for i,test_set in enumerate(['Novartis', 'Literature', 'val_split']):\n",
    "\n",
    "    df_ml = test_ml_model(baseline_models, fp_data[test_set], fp_data[test_set]['y'],test_set)\n",
    "    df_gcn = test_graph_model(graph_models, loaders[test_set],test_set)\n",
    "    df= pd.concat([df_ml.drop(columns=['Dataset', 'pKa_true']),df_gcn],axis=1)\n",
    "    df= pd.concat([df_gcn],axis=1)\n",
    "    torch.cuda.empty_cache()\n",
    "    if i == 0:\n",
    "        df_res = df\n",
    "    else:\n",
    "        df_res = pd.concat([df_res,df])\n",
    "display(df_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test= compute_stats(df_res, 'Dataset', 'pKa_true')\n",
    "test.to_csv(f'{imgdir}/stat_metrics.csv')\n",
    "display(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot best model\n",
    "Plot the predictions of the best models for the validation and the two testsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(df, x_column, y_column):\n",
    "    y = df[x_column]\n",
    "    y_hat = df[y_column]\n",
    "    stat_info = f\"\"\"\n",
    "        $r^2$ = {r2_score(y, y_hat): .2f}\n",
    "        $MAE$ = {mean_absolute_error(y, y_hat): .2f}\n",
    "        $RMSE$ = {mean_squared_error(y, y_hat): .2f}\n",
    "        \"\"\"\n",
    "        # r = 0.78 [0.74, 0.81]\n",
    "    g = sns.JointGrid(data=df, x=x_column, y=y_column, xlim=(2,12), ylim=(2,12), height=3.125)\n",
    "    g.plot_joint(sns.regplot)\n",
    "    g.plot_marginals(sns.kdeplot, shade=True)\n",
    "    g.ax_joint.text(0, 1, stat_info, size='x-small', ha='left', va=\"top\", transform = g.ax_joint.transAxes)\n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_context('paper')\n",
    "d = df_res\n",
    "model='GCN_prot_edge'\n",
    "for dataset in d['Dataset'].unique():\n",
    "# for dataset, model in zip(['Novartis','Literature'],['GCN_pair_edge', 'GCN_deprot_no-edge']):\n",
    "    print(dataset)\n",
    "    g = plot_results(d[d['Dataset']== dataset], 'pKa_true', model)\n",
    "    g.set_axis_labels('pKa (true)', 'gcn_pair_edge')\n",
    "    plt.savefig(f'{imgdir}/regression_{dataset}_gcn_pair_edge.pdf', bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    plt.figure(figsize=(3.125,3.125))\n",
    "    sns.residplot(data=df_res[df_res['Dataset']==dataset],x='pKa_true', y=model, lowess=True)\n",
    "    plt.ylabel('Error')\n",
    "#     plt.title('gcn_pair_edge')\n",
    "    plt.savefig(f'{imgdir}/residuals_{dataset}_gcn_pair_edge.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GCN training progress\n",
    "\n",
    "store training losses in DataFrame and"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x,y in list([['prot','edge'],['prot','no-edge']]):\n",
    "    df_prog=pd.DataFrame(graph_models[x][y].checkpoint['progress_table'])\n",
    "#     df_prog=pd.DataFrame(graph_models_cv[x][y][1].checkpoint['progress_table'])\n",
    "    #plot learning\n",
    "    fig, ax = plt.subplots()\n",
    "    fig.set_size_inches(3.125,3.125)\n",
    "    sns.lineplot(x='epoch',y='train_loss', label='Train Loss',data=df_prog,ax=ax)\n",
    "    sns.lineplot(x='epoch',y='test_loss',label='Validation Loss',data=df_prog,ax=ax)\n",
    "    ax.set_ylabel(\"Loss (MAE)\")\n",
    "    ax.set_xlabel(\"Epoch\")\n",
    "    ax.set_xlim(left=0, right=2000)\n",
    "    ax.set_ylim(top=1.75, bottom=0)\n",
    "#     plt.title(f'training progress of gcn_{x}_{y} model')\n",
    "    plt.savefig(f'{imgdir}/training_progress_gcn_{x}_{y}.pdf',bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Feature impact\n",
    "\n",
    "Importances of gcn_prot_edge'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def boxplot(attr_data):\n",
    "#     plt.figure(figsize=(3.125,6.25))\n",
    "#     sns.boxplot(x=\"value\", y=\"variable\",\n",
    "#                 orient=\"h\",\n",
    "#                 data=attr_data,\n",
    "#                 whis=[0, 100], width=.6)\n",
    "\n",
    "#     # Add in points to show each observation\n",
    "#     sns.stripplot(x=\"value\", y=\"variable\",\n",
    "#                 orient=\"h\",\n",
    "#                 data=attr_data,\n",
    "#                 size=4, color=\".3\", linewidth=0)\n",
    "#     plt.ylabel('')\n",
    "\n",
    "# # types = ['prot','deprot','pair']\n",
    "# types = ['prot']\n",
    "# f_modes= ['no-edge','edge']\n",
    "# for data_type in types:\n",
    "#     for f_mode in f_modes: \n",
    "#         model = graph_models[data_type][f_mode]\n",
    "#         dataset = graph_data['train_split']\n",
    "#         ig = IntegratedGradients(model)\n",
    "#         attr_pre_df = calc_importances(ig, dataset, 100, list_node_features, list_edge_features) #adjust number of random samples\n",
    "\n",
    "#         attr_pre_df.iloc[:, 1:]=attr_pre_df.iloc[:, 1:].abs()\n",
    "#         attr_df=attr_pre_df.groupby('ID').max()\n",
    "#         attr_data = pd.melt(attr_df)\n",
    "        \n",
    "#         if data_type== 'pair':\n",
    "#             split = len(attr_data.variable.unique())//2\n",
    "#             attr_data1 = pd.melt(attr_df.iloc[:,0:split])\n",
    "#             attr_data2 = pd.melt(attr_df.iloc[:,split:])\n",
    "        \n",
    "#             boxplot(attr_data1)\n",
    "# #             plt.title(f'gcn_{data_type}_1_{f_mode}')\n",
    "#             plt.savefig(f'{imgdir}/importances_{data_type}_1_{f_mode}.pdf', bbox_inches='tight')\n",
    "#             plt.show()\n",
    "#             boxplot(attr_data2)\n",
    "# #             plt.title(f'gcn_{data_type}_2_{f_mode}')\n",
    "#             plt.savefig(f'{imgdir}/importances_{data_type}_2_{f_mode}.pdf', bbox_inches='tight')\n",
    "#             plt.show()\n",
    "            \n",
    "#         else:\n",
    "#             boxplot(attr_data)\n",
    "# #             plt.title(f'gcn_{data_type}_{f_mode}')\n",
    "#             plt.savefig(f'{imgdir}/importances_{data_type}_{f_mode}.pdf', bbox_inches='tight')\n",
    "#             plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Metrics by tanimoto similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1= pd.concat([df_res[['Dataset', 'pKa_true']],df_res.loc[:,(df_res.columns.str.startswith('GCN'))]],axis=1)\n",
    "for data_set in ['Novartis', 'Literature']:\n",
    "    df = x1[x1['Dataset']==data_set].copy()\n",
    "    df['similarity'] = dataset_dfs[data_set].loc[:,'Similarity_max']\n",
    "    df.sort_values(by=['similarity'], inplace=True)\n",
    "\n",
    "    res=[]\n",
    "    tanimoto=[]\n",
    "    maximum=0\n",
    "\n",
    "    for i in range(2,len(df)):\n",
    "        df2 = df.iloc[:i,:]\n",
    "        new_maximum = df2['similarity'].max()\n",
    "        if new_maximum <= maximum:\n",
    "            tanimoto[-1]= new_maximum\n",
    "            res[-1]= compute_stats(df2, 'Dataset', 'pKa_true',col_exclude=['similarity'])\n",
    "        else: \n",
    "            tanimoto.append(new_maximum)\n",
    "            res.append(compute_stats(df2, 'Dataset', 'pKa_true', col_exclude=['similarity']))\n",
    "        maximum=new_maximum\n",
    "    result = pd.concat((res), keys=tanimoto)\n",
    "    result\n",
    "\n",
    "    # X=result['Novartis'].loc[(slice(None),'pKa_gcn_prot_edge'),:].reset_index()\n",
    "    X=result[data_set].reset_index()\n",
    "    plt.figure(figsize=(6.25,4))\n",
    "    ax = sns.scatterplot(x='level_0', y=\"RMSE\", hue='level_1', palette='colorblind', data=X)\n",
    "    legend = ax.legend()\n",
    "    legend.texts[0] = ''\n",
    "    plt.xlabel('Similarity')\n",
    "    plt.savefig(f'{imgdir}/RMSE_sim_{data_set}.pdf')\n",
    "    \n",
    "    x2= x1\n",
    "    df = x2[x2['Dataset']==data_set].copy()\n",
    "    df['similarity'] = dataset_dfs[data_set].loc[:,'Similarity_max']\n",
    "    df.sort_values(by=['similarity'], inplace=True)\n",
    "    \n",
    "    df = df.loc[:,('pKa_true','GCN_pair_edge','similarity')]\n",
    "\n",
    "    df['Error']= df['GCN_pair_edge']-df['pKa_true']\n",
    "\n",
    "    sims=[]\n",
    "    step_size=0.15\n",
    "    for sim in df['similarity']:\n",
    "        x=1\n",
    "        while sim < x:\n",
    "            x+= -step_size\n",
    "        sims.append(f'< {round(np.clip(x+step_size,0,1),3)}')\n",
    "    df['group']=sims            \n",
    "\n",
    "    plt.figure(figsize=(6.25/2,2.5))\n",
    "    sns.boxplot(x=\"group\", y=\"Error\",\n",
    "                orient=\"v\",\n",
    "\n",
    "                whis=[0, 100], width=.6,\n",
    "                data=df\n",
    "               )\n",
    "    # Add in points to show each observation\n",
    "    sns.stripplot(x=\"group\", y=\"Error\",\n",
    "                orient=\"v\",\n",
    "                data=df,\n",
    "                  size=4, color=\".3\", linewidth=0)\n",
    "    plt.xlabel('Similarity')\n",
    "    plt.ylabel('Error [pKa units]')\n",
    "    plt.savefig(f'{imgdir}/error_sim_bloxplot_{data_set}.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Outliers top list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_2d_molecule(m):\n",
    "  copy = Mol(m)\n",
    "  copy.Compute2DCoords(clearConfs=True)\n",
    "  return copy\n",
    "\n",
    "def group_by_range(series, range_list, decimal=1):\n",
    "    group_labels=[]\n",
    "    for x in series:\n",
    "        i=0\n",
    "        while x > range_list[i]:\n",
    "            i+=1\n",
    "        group_labels.append(round(range_list[i],decimal))\n",
    "    return group_labels \n",
    "\n",
    "data_set=['Novartis', 'Literature']\n",
    "best=[True, False]\n",
    "for data_set in data_set:\n",
    "    trues= df_res[df_res.Dataset==data_set].pKa_true\n",
    "    preds= df_res[df_res.Dataset==data_set].GCN_pair_edge\n",
    "    diffs = []\n",
    "    errors = []\n",
    "    for pred, true in zip(preds,trues):\n",
    "        diffs.append(pred-true)\n",
    "        errors.append(abs(pred-true))\n",
    "    res = pd.concat((pd.DataFrame({'differences':diffs}),pd.DataFrame({'errors':errors}), dataset_dfs['Novartis'].loc[:,('pKa','marvin_atom','protonated', 'deprotonated', 'ID','Similarity_max')]),axis=1)\n",
    "    \n",
    "    res_e=res.loc[:, ('errors','pKa','Similarity_max')]\n",
    "    res_e['pKa']=group_by_range(res_e['pKa'],list(range(2,14,2)))\n",
    "    res_e['Similarity']=group_by_range(res['Similarity_max'],np.arange(0.0,1.2,0.2))\n",
    "    res_e=res_e.loc[:, ('errors','pKa','Similarity')]\n",
    "    res_e=res_e.groupby(['Similarity','pKa']).mean().unstack()\n",
    "#     display(res_e)\n",
    "    \n",
    "    plt.figure(figsize=(3.125,2.5))\n",
    "    sns.heatmap(res_e['errors'], cmap='RdYlGn_r', vmin=0,vmax=1.50)\n",
    "    plt.savefig(f'{imgdir}/error_heatmap_{data_set}.pdf', bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    for mod in best:    \n",
    "        res.sort_values(by=['errors'], inplace=True, ascending=mod)\n",
    "        num=6\n",
    "        img=Draw.MolsToGridImage(res.protonated[:num].map(get_2d_molecule),\n",
    "                                 molsPerRow=3,\n",
    "                                 subImgSize=(400,350),\n",
    "                                 useSVG=True,\n",
    "                                 highlightAtomLists=[[int(i)] for i in res.marvin_atom[:num]],\n",
    "                                 legends=[f\"error:  {round(x[1],2)}, pKa:  {x[0]}, sim: {x[2]:.3f}\" for x in zip(res.pKa[:num],res.differences[:num], res.Similarity_max[:num])])\n",
    "\n",
    "        display(img)\n",
    "        name_dict={True:'best',False:'outlier'}\n",
    "        with open(f'{imgdir}/grid_{data_set}_{name_dict[mod]}.svg', 'w') as f:\n",
    "            f.write(img.data)\n",
    "    # res.head()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2238d854a1993a20f5a2e769920d74e68befec1db0b55829c688fae57b1385d3"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('pkasolver': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
